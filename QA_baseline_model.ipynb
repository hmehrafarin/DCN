{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "QA_baseline_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2baIdf6nu0s",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a2056dac-fe38-4414-9772-be047d9a00da"
      },
      "source": [
        "#@title Importing Libraries\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "from keras.layers import Dense ,LSTM,concatenate,Input,Flatten\n",
        "from keras import backend as K\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, Dense, Activation, merge, Flatten, Reshape\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2OmDyo4w4yh",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HuzeI7wnu04",
        "colab_type": "text"
      },
      "source": [
        "# Problem Forumlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfBjs6fInu06",
        "colab_type": "text"
      },
      "source": [
        "### Model is provided two inputs question_vector and document_vector and asked to predict the start and end index of answer in the document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrl8YkXhnu08",
        "colab_type": "text"
      },
      "source": [
        "# Load word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQwck9VKnu09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_path = \"/content/drive/My Drive/Deep Data/data/glove.trimmed.100.npz\"\n",
        "train = pd.read_json('/content/drive/My Drive/Deep Data/download/squad/train-v1.1.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs8y2OG3nu1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = []\n",
        "questions = []\n",
        "answers = []\n",
        "titles = []\n",
        "answer_start_indexs = []\n",
        "answer_end_indexs = []\n",
        "def get_attributes(item):\n",
        "    data = item['data']\n",
        "    title = data['title']\n",
        "    for paragraph in data['paragraphs']:\n",
        "        for qas in paragraph['qas']:\n",
        "            answer = qas['answers'][0]['text']\n",
        "            answer_start_index = qas['answers'][0]['answer_start']\n",
        "            answer_end_index = answer_start_index + len(answer.split(' ')) - 1\n",
        "            answers.append(qas['answers'][0]['text'])\n",
        "            questions.append(qas['question'])\n",
        "            documents.append(paragraph['context'])\n",
        "            answer_start_indexs.append(answer_start_index)\n",
        "            answer_end_indexs.append(answer_end_index)\n",
        "            \n",
        "            titles.append(title)\n",
        "            \n",
        "def build_dataframe(train):\n",
        "    train.apply(get_attributes, axis = 1)\n",
        "    train_df = pd.DataFrame({\n",
        "    'documents':documents,\n",
        "    'questions': questions,\n",
        "    'answers': answers,\n",
        "    'titles': titles,\n",
        "     'answer_end_indexs': answer_end_indexs,\n",
        "    'answer_start_indexs': answer_start_indexs\n",
        "})\n",
        "    return train_df\n",
        "    \n",
        "train_df = build_dataframe(train)\n",
        "train_df = train_df.head(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWX5H1Xonu1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "4837cc48-8026-4de8-883d-bd630e550634"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>documents</th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "      <th>titles</th>\n",
              "      <th>answer_end_indexs</th>\n",
              "      <th>answer_start_indexs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>517</td>\n",
              "      <td>515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>192</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>281</td>\n",
              "      <td>279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>387</td>\n",
              "      <td>381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>98</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           documents  ... answer_start_indexs\n",
              "0  Architecturally, the school has a Catholic cha...  ...                 515\n",
              "1  Architecturally, the school has a Catholic cha...  ...                 188\n",
              "2  Architecturally, the school has a Catholic cha...  ...                 279\n",
              "3  Architecturally, the school has a Catholic cha...  ...                 381\n",
              "4  Architecturally, the school has a Catholic cha...  ...                  92\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjfQ6MO3nu1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_length(sentences):\n",
        "    max_length = 0\n",
        "    for sentence in sentences:\n",
        "        length_of_sentence = len(sentence)\n",
        "        if length_of_sentence > max_length:\n",
        "            max_length = length_of_sentence\n",
        "    return max_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mzX5jrwnu1j",
        "colab_type": "text"
      },
      "source": [
        "# Extract Entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6mcxnMYnu1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.head(2000)\n",
        "documents = list(train_df[\"documents\"])\n",
        "questions = list(train_df[\"questions\"])\n",
        "answer_start_indexs = train_df[\"answer_start_indexs\"].values\n",
        "answer_end_indexs = train_df[\"answer_end_indexs\"].values\n",
        "sentences = documents + questions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liEIzitknu1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions = train_df['questions'].values\n",
        "answers = train_df['answers'].values\n",
        "documents = train_df['documents'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDoggBJynu10",
        "colab_type": "text"
      },
      "source": [
        "# Vectorize Question, Answer and Context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG7qyn7Onu11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorized_data = []\n",
        "def vectorize(item):\n",
        "    tokenizer = Tokenizer(\n",
        "    num_words = 20000,\n",
        "    filters = '\"#$%&()*+-/:;<=>@[\\]^_`{|}~'   \n",
        ")\n",
        "        \n",
        "    documents = list(item[\"documents\"])\n",
        "    questions = list(item[\"questions\"])\n",
        "    answers = list(item['answers'])\n",
        "    start_index = list(item['answer_start_indexs'])\n",
        "    end_index = list(item['answer_end_indexs'])\n",
        "    sentences = documents + questions\n",
        "    \n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    questions_tokenized = tokenizer.texts_to_sequences(questions)\n",
        "    answers_tokenized = tokenizer.texts_to_sequences(answers)\n",
        "    documents_tokenized = tokenizer.texts_to_sequences(documents)\n",
        "    \n",
        "    questions_padded = pad_sequences(questions_tokenized, maxlen = 80, padding = 'post')\n",
        "    answers_padded = pad_sequences(answers_tokenized, maxlen = 1405, padding = 'post')\n",
        "    documents_padded = pad_sequences(documents_tokenized, maxlen = 1405, padding = 'post')\n",
        "    for i in range(0, len(documents)):\n",
        "        vectorized_data.append([questions_padded[i], answers_padded[i], documents_padded[i], start_index[i], end_index[i] ])\n",
        "    \n",
        "train_df.groupby('documents').apply(vectorize)\n",
        "vectorized_data = pd.DataFrame(vectorized_data)\n",
        "vectorized_data.rename(columns = {0: 'question_vector', 1: 'answers_vector', 2: 'documents_vector', 3: 'answer_start_indexs', 4: 'answer_end_indexs' },inplace = True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0WwlqTBnu16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "90ae9394-81ff-4695-f430-32667f474e51"
      },
      "source": [
        "vectorized_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_vector</th>\n",
              "      <th>answers_vector</th>\n",
              "      <th>documents_vector</th>\n",
              "      <th>answer_start_indexs</th>\n",
              "      <th>answer_end_indexs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[89, 93, 94, 2, 95, 1, 4, 18, 19, 88, 13, 16, ...</td>\n",
              "      <td>[31, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>[4, 18, 19, 9, 27, 8, 28, 29, 2, 30, 1, 31, 32...</td>\n",
              "      <td>56</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[8, 90, 97, 98, 2, 5, 21, 7, 88, 13, 16, 99, 1...</td>\n",
              "      <td>[34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>[4, 18, 19, 9, 27, 8, 28, 29, 2, 30, 1, 31, 32...</td>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[22, 89, 101, 9, 2, 6, 92, 13, 16, 102, 0, 0, ...</td>\n",
              "      <td>[38, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>[4, 18, 19, 9, 27, 8, 28, 29, 2, 30, 1, 31, 32...</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[103, 104, 8, 23, 24, 17, 2, 6, 92, 88, 13, 10...</td>\n",
              "      <td>[51, 23, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[4, 18, 19, 9, 27, 8, 28, 29, 2, 30, 1, 31, 32...</td>\n",
              "      <td>284</td>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[90, 17, 2, 25, 26, 1, 13, 106, 6, 91, 0, 0, 0...</td>\n",
              "      <td>[71, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>[4, 18, 19, 9, 27, 8, 28, 29, 2, 30, 1, 31, 32...</td>\n",
              "      <td>535</td>\n",
              "      <td>536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     question_vector  ... answer_end_indexs\n",
              "0  [89, 93, 94, 2, 95, 1, 4, 18, 19, 88, 13, 16, ...  ...                57\n",
              "1  [8, 90, 97, 98, 2, 5, 21, 7, 88, 13, 16, 99, 1...  ...                73\n",
              "2  [22, 89, 101, 9, 2, 6, 92, 13, 16, 102, 0, 0, ...  ...               158\n",
              "3  [103, 104, 8, 23, 24, 17, 2, 6, 92, 88, 13, 10...  ...               286\n",
              "4  [90, 17, 2, 25, 26, 1, 13, 106, 6, 91, 0, 0, 0...  ...               536\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsCu_z5Jnu2B",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi-3uIuLnu2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question_input = Input(shape=(80,), dtype='int32', name='question_input')\n",
        "context_input =  Input(shape=(1405,), dtype='int32', name='context_input')\n",
        "\n",
        "questionEmbd = Embedding(output_dim=100, input_dim=20000,\n",
        "                         mask_zero=False, \n",
        "                         input_length=80, trainable=False)(question_input)\n",
        "\n",
        "\n",
        "contextEmb = Embedding(output_dim=100, input_dim=20000,\n",
        "                         mask_zero=False,\n",
        "                         input_length=1405, trainable=False)(context_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5-xKsHqnu2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = Bidirectional(LSTM(80, return_sequences=True))(questionEmbd)\n",
        "D = Bidirectional(LSTM(40, return_sequences=True))(contextEmb)\n",
        "Q_flatten = Flatten()(Q)\n",
        "D_flatten = Flatten()(D)\n",
        "merged = concatenate([D_flatten, Q_flatten])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5gQDIUvnu2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "ecbcc69e-fedc-42c1-8bc4-43e1dce078a5"
      },
      "source": [
        "output1 = Dense(1,activation='sigmoid')(merged)\n",
        "l2_merged = concatenate([merged, output1])\n",
        "output2 = Dense(1,activation='sigmoid')(l2_merged)\n",
        "\n",
        "model = Model(inputs=[question_input,context_input], outputs = [output1,output2])\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "context_input (InputLayer)      (None, 1405)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question_input (InputLayer)     (None, 80)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1405, 100)    2000000     context_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 80, 100)      2000000     question_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 1405, 80)     45120       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 80, 160)      115840      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 112400)       0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 12800)        0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 125200)       0           flatten_2[0][0]                  \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            125201      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 125201)       0           concatenate_1[0][0]              \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            125202      concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 4,411,363\n",
            "Trainable params: 411,363\n",
            "Non-trainable params: 4,000,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsKVFHTgnu2S",
        "colab_type": "text"
      },
      "source": [
        "# Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYpUNkcOnu2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions_padded = np.array(vectorized_data['question_vector'].values.tolist())\n",
        "documents_padded = np.array(vectorized_data['documents_vector'].values.tolist())\n",
        "answer_begin = np.array(vectorized_data['answers_vector'].values.tolist())\n",
        "answer_start_indexs = np.array(vectorized_data['answer_start_indexs'].values.tolist())\n",
        "answer_end_indexs = np.array(vectorized_data['answer_end_indexs'].values.tolist())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqxi-1AWnu2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit([questions_padded, documents_padded],[answer_start_indexs,  answer_end_indexs] ,\n",
        "                    epochs=10,\n",
        "                    batch_size=300)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}